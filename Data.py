"""
===============================================================================
ENHANCED CUSTOMER LOYALTY ANALYSIS DASHBOARD - PRODUCTION VERSION
===============================================================================
Features:
- PDF data extraction with multiple fallback methods
- Advanced data validation and cleaning
- Professional interactive dashboard
- Comprehensive insights generation
- Error handling and logging
- Export capabilities
===============================================================================
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime, timedelta
import warnings
import os
import sys
from matplotlib.patches import FancyBboxPatch, Rectangle, Circle
from matplotlib.gridspec import GridSpec
import traceback
import math
from pathlib import Path

warnings.filterwarnings('ignore')

# ============================================================================
# CONFIGURATION
# ============================================================================

class Config:
    """Configuration settings"""
    # File paths
    DATA_FILE_PATH = r'D:\LLM1\work1\Data.pdf'
    OUTPUT_DIR = 'output'

    # Professional color palette
    COLORS = {
        'primary': '#2E86AB',
        'secondary': '#A23B72',
        'success': '#18A999',
        'warning': '#F18F01',
        'danger': '#C73E1D',
        'dark': '#2B2D42',
        'light': '#EDF2F4',
        'accent1': '#6A994E',
        'accent2': '#E9C46A',
        'gradient1': '#667EEA',
        'gradient2': '#764BA2',
    }

    # Chart settings
    FIGSIZE = (24, 16)
    DPI = 150
    STYLE = 'seaborn-v0_8-whitegrid'

# ============================================================================
# DATA LOADING AND PARSING
# ============================================================================

class DataLoader:
    """Handle data loading from various sources"""

    @staticmethod
    def load_from_pdf(file_path):
        """
        Load data from PDF with multiple fallback methods
        """
        print(f"\nüìÑ Attempting to load data from: {file_path}")

        if not os.path.exists(file_path):
            print(f"‚ùå File not found: {file_path}")
            return None

        # Method 1: Try tabula
        try:
            import tabula
            print("   ‚Üí Trying tabula-py...")
            dfs = tabula.read_pdf(file_path, pages='all', multiple_tables=False)
            if dfs and len(dfs) > 0:
                df = dfs[0] if isinstance(dfs, list) else dfs
                print(f"   ‚úÖ Successfully loaded with tabula: {len(df)} rows")
                return df
        except ImportError:
            print("   ‚ö†Ô∏è tabula-py not installed (pip install tabula-py)")
        except Exception as e:
            print(f"   ‚ö†Ô∏è tabula failed: {str(e)[:100]}")

        # Method 2: Try camelot
        try:
            import camelot
            print("   ‚Üí Trying camelot...")
            tables = camelot.read_pdf(file_path, pages='all', flavor='stream')
            if len(tables) > 0:
                df = tables[0].df
                print(f"   ‚úÖ Successfully loaded with camelot: {len(df)} rows")
                return df
        except ImportError:
            print("   ‚ö†Ô∏è camelot-py not installed (pip install camelot-py[cv])")
        except Exception as e:
            print(f"   ‚ö†Ô∏è camelot failed: {str(e)[:100]}")

        # Method 3: Try pdfplumber
        try:
            import pdfplumber
            print("   ‚Üí Trying pdfplumber...")
            with pdfplumber.open(file_path) as pdf:
                all_tables = []
                for page in pdf.pages:
                    tables = page.extract_tables()
                    all_tables.extend(tables)

                if all_tables:
                    # Convert first table to DataFrame
                    df = pd.DataFrame(all_tables[0][1:], columns=all_tables[0][0])
                    print(f"   ‚úÖ Successfully loaded with pdfplumber: {len(df)} rows")
                    return df
        except ImportError:
            print("   ‚ö†Ô∏è pdfplumber not installed (pip install pdfplumber)")
        except Exception as e:
            print(f"   ‚ö†Ô∏è pdfplumber failed: {str(e)[:100]}")

        print("   ‚ùå All PDF extraction methods failed")
        return None

    @staticmethod
    def load_from_csv(file_path):
        """Load data from CSV"""
        try:
            df = pd.read_csv(file_path)
            print(f"‚úÖ Loaded CSV: {len(df)} rows")
            return df
        except Exception as e:
            print(f"‚ùå CSV loading failed: {e}")
            return None

    @staticmethod
    def create_sample_data(n_samples=200):
        """
        Create realistic sample data for demonstration
        """
        print(f"\nüé≤ Creating enhanced sample data ({n_samples} records)...")

        np.random.seed(42)

        # Generate dates (6 months)
        dates = []
        for month in range(1, 7):
            for _ in range(n_samples // 6):
                day = np.random.randint(1, 28)
                dates.append(datetime(2024, month, day))

        # Pad to exact number
        while len(dates) < n_samples:
            dates.append(datetime(2024, np.random.randint(1, 7), np.random.randint(1, 28)))

        dates = sorted(dates[:n_samples])

        # Generate realistic revenue (with seasonality)
        base_revenue = np.random.exponential(400, n_samples) + 100
        seasonality = np.sin(np.linspace(0, 2*np.pi, n_samples)) * 100 + 100
        revenues = base_revenue + seasonality
        revenues = np.clip(revenues, 50, 3000)

        # Generate costs (60-80% of revenue)
        cost_ratios = np.random.beta(2, 2, n_samples) * 0.3 + 0.5
        costs = revenues * cost_ratios

        # Ad spend (part of costs)
        ad_spend = costs * np.random.uniform(0.3, 0.6, n_samples)

        # Satisfaction (correlated with profit margin)
        profit_margins = (revenues - costs) / revenues
        satisfaction_base = (profit_margins * 5 + 5).clip(1, 10)
        satisfaction = satisfaction_base + np.random.normal(0, 1, n_samples)
        satisfaction = satisfaction.clip(1, 10).round().astype(int)

        # Conversions (correlated with ad spend)
        conversions = (ad_spend / 50 + np.random.poisson(3, n_samples)).clip(0, 25)

        # Categorical variables with realistic distributions
        campaign_types = np.random.choice(
            ['Premium', 'Standard', 'Seasonal', 'Limited', 'Flash Sale'],
            n_samples,
            p=[0.25, 0.35, 0.2, 0.1, 0.1]
        )

        customer_statuses = np.random.choice(
            ['New', 'Returning'],
            n_samples,
            p=[0.35, 0.65]
        )

        channels = np.random.choice(
            ['Google Ads', 'Email', 'Instagram', 'Facebook', 'Referral', 'Organic', 'LinkedIn'],
            n_samples,
            p=[0.25, 0.15, 0.2, 0.15, 0.1, 0.1, 0.05]
        )

        regions = np.random.choice(
            ['North', 'South', 'East', 'West', 'Central'],
            n_samples,
            p=[0.25, 0.2, 0.2, 0.2, 0.15]
        )

        service_types = np.random.choice(
            ['Premium', 'Standard', 'Basic', 'Enterprise'],
            n_samples,
            p=[0.3, 0.4, 0.2, 0.1]
        )

        # Create DataFrame
        df = pd.DataFrame({
            'Date': dates,
            'Revenue': np.round(revenues, 2),
            'Cost': np.round(costs, 2),
            'Ad_Spend': np.round(ad_spend, 2),
            'Conversions': conversions.astype(int),
            'Customer_Satisfaction': satisfaction,
            'Campaign_Type': campaign_types,
            'Customer_Status': customer_statuses,
            'Channel': channels,
            'Region': regions,
            'Service_Type': service_types,
        })

        print(f"‚úÖ Sample data created successfully")
        return df

# ============================================================================
# DATA CLEANING AND VALIDATION
# ============================================================================

class DataCleaner:
    """Handle data cleaning and validation"""

    @staticmethod
    def clean_and_validate(df):
        """
        Comprehensive data cleaning and validation
        """
        print("\nüßπ Cleaning and validating data...")

        if df is None or len(df) == 0:
            print("‚ùå No data to clean")
            return None

        df = df.copy()
        initial_rows = len(df)

        # 1. Clean column names
        df.columns = df.columns.str.strip().str.replace(' ', '_').str.replace('-', '_')
        print(f"   ‚úì Cleaned column names: {list(df.columns)}")

        # 2. Handle Date column
        date_col = None
        for col in ['Date', 'date', 'DATE', 'Transaction_Date']:
            if col in df.columns:
                date_col = col
                break

        if date_col:
            df['Date'] = pd.to_datetime(df[date_col], errors='coerce')
            null_dates = df['Date'].isna().sum()
            if null_dates > 0:
                print(f"   ‚ö†Ô∏è Removed {null_dates} rows with invalid dates")
                df = df.dropna(subset=['Date'])
        else:
            print("   ‚ö†Ô∏è No date column found, creating synthetic dates")
            df['Date'] = pd.date_range(start='2024-01-01', periods=len(df), freq='D')

        # 3. Handle numeric columns
        numeric_mappings = {
            'Revenue': ['Revenue', 'revenue', 'Sales', 'sales'],
            'Cost': ['Cost', 'cost', 'Expense', 'expense'],
            'Ad_Spend': ['Ad_Spend', 'AdSpend', 'ad_spend', 'Marketing_Spend'],
            'Conversions': ['Conversions', 'conversions', 'Leads'],
            'Customer_Satisfaction': ['Customer_Satisfaction', 'Satisfaction', 'Rating', 'Score'],
        }

        for target_col, possible_names in numeric_mappings.items():
            found = False
            for name in possible_names:
                if name in df.columns:
                    df[target_col] = pd.to_numeric(df[name], errors='coerce')
                    found = True
                    break

            if not found and target_col not in df.columns:
                # Generate synthetic data for missing columns
                if target_col == 'Revenue':
                    df[target_col] = np.random.uniform(100, 1000, len(df))
                elif target_col == 'Cost':
                    df[target_col] = df.get('Revenue', np.random.uniform(100, 1000, len(df))) * 0.6
                elif target_col == 'Ad_Spend':
                    df[target_col] = df.get('Cost', np.random.uniform(50, 500, len(df))) * 0.4
                elif target_col == 'Conversions':
                    df[target_col] = np.random.randint(0, 20, len(df))
                elif target_col == 'Customer_Satisfaction':
                    df[target_col] = np.random.randint(1, 11, len(df))

                print(f"   ‚ö†Ô∏è Generated synthetic {target_col}")

        # 4. Handle categorical columns
        categorical_mappings = {
            'Campaign_Type': ['Campaign_Type', 'Campaign', 'campaign_type'],
            'Customer_Status': ['Customer_Status', 'Customer_Type', 'Status'],
            'Channel': ['Channel', 'Source', 'channel'],
            'Region': ['Region', 'Location', 'region'],
            'Service_Type': ['Service_Type', 'Service', 'Product_Type'],
        }

        for target_col, possible_names in categorical_mappings.items():
            found = False
            for name in possible_names:
                if name in df.columns:
                    df[target_col] = df[name].astype(str).str.strip()
                    found = True
                    break

            if not found and target_col not in df.columns:
                # Generate synthetic categorical data
                if target_col == 'Campaign_Type':
                    df[target_col] = np.random.choice(['Premium', 'Standard', 'Seasonal'], len(df))
                elif target_col == 'Customer_Status':
                    df[target_col] = np.random.choice(['New', 'Returning'], len(df))
                elif target_col == 'Channel':
                    df[target_col] = np.random.choice(['Google', 'Email', 'Social'], len(df))
                elif target_col == 'Region':
                    df[target_col] = np.random.choice(['North', 'South', 'East', 'West'], len(df))
                elif target_col == 'Service_Type':
                    df[target_col] = np.random.choice(['Premium', 'Standard', 'Basic'], len(df))

                print(f"   ‚ö†Ô∏è Generated synthetic {target_col}")

        # 5. Remove rows with critical missing values
        critical_cols = ['Date', 'Revenue']
        df = df.dropna(subset=critical_cols)

        # 6. Remove outliers (optional)
        for col in ['Revenue', 'Cost', 'Ad_Spend']:
            if col in df.columns:
                Q1 = df[col].quantile(0.25)
                Q3 = df[col].quantile(0.75)
                IQR = Q3 - Q1
                lower_bound = Q1 - 3 * IQR
                upper_bound = Q3 + 3 * IQR
                outliers = ((df[col] < lower_bound) | (df[col] > upper_bound)).sum()
                if outliers > 0:
                    print(f"   ‚ö†Ô∏è Found {outliers} outliers in {col} (kept them)")

        # 7. Calculate derived metrics
        df['Profit'] = df['Revenue'] - df['Cost']
        df['Profit_Margin'] = np.where(
            df['Revenue'] > 0,
            (df['Profit'] / df['Revenue']) * 100,
            0
        )

        # CLV Score (simple calculation)
        df['CLV_Score'] = df.apply(
            lambda x: x['Revenue'] * 2.5 if x['Customer_Status'] == 'Returning' else x['Revenue'] * 1.2,
            axis=1
        )

        # ROI from Ad Spend
        df['Ad_ROI'] = np.where(
            df['Ad_Spend'] > 0,
            ((df['Revenue'] - df['Ad_Spend']) / df['Ad_Spend']) * 100,
            0
        )

        # Conversion Rate
        df['Conversion_Rate'] = np.where(
            df['Ad_Spend'] > 0,
            (df['Conversions'] / (df['Ad_Spend'] / 10)) * 100,
            0
        ).clip(0, 100)

        # Month and Quarter for time series
        df['Month'] = df['Date'].dt.to_period('M').astype(str)
        df['Quarter'] = df['Date'].dt.to_period('Q').astype(str)
        df['Month_Name'] = df['Date'].dt.strftime('%b %Y')

        final_rows = len(df)
        removed_rows = initial_rows - final_rows

        print(f"\n‚úÖ Data cleaning completed:")
        print(f"   ‚Ä¢ Initial rows: {initial_rows}")
        print(f"   ‚Ä¢ Final rows: {final_rows}")
        print(f"   ‚Ä¢ Removed: {removed_rows}")
        print(f"   ‚Ä¢ Columns: {len(df.columns)}")

        return df

    @staticmethod
    def print_data_quality_report(df):
        """Print comprehensive data quality report"""
        print("\n" + "="*80)
        print("üìä DATA QUALITY REPORT")
        print("="*80)

        print(f"\nüìÖ Date Range: {df['Date'].min().date()} to {df['Date'].max().date()}")
        print(f"üìà Total Records: {len(df):,}")

        print("\nüî¢ NUMERIC COLUMNS SUMMARY:")
        numeric_cols = df.select_dtypes(include=[np.number]).columns
        for col in numeric_cols:
            print(f"\n   {col}:")
            print(f"      Mean: {df[col].mean():.2f}")
            print(f"      Median: {df[col].median():.2f}")
            print(f"      Min: {df[col].min():.2f}")
            print(f"      Max: {df[col].max():.2f}")
            print(f"      Missing: {df[col].isna().sum()} ({df[col].isna().sum()/len(df)*100:.1f}%)")

        print("\nüìë CATEGORICAL COLUMNS:")
        categorical_cols = df.select_dtypes(include=['object']).columns
        for col in categorical_cols:
            unique_count = df[col].nunique()
            print(f"\n   {col}: {unique_count} unique values")
            top_values = df[col].value_counts().head(5)
            for val, count in top_values.items():
                print(f"      ‚Ä¢ {val}: {count} ({count/len(df)*100:.1f}%)")

        print("\n" + "="*80)

# ============================================================================
# ENHANCED PROFESSIONAL DASHBOARD
# ============================================================================

class EnhancedLoyaltyDashboard:
    """Enhanced Professional Dashboard with advanced visualizations"""

    def __init__(self, df, config=None):
        self.df = df.copy()
        self.config = config or Config()
        self.fig = None
        self.insights = []

        # Apply style
        plt.style.use(self.config.STYLE)
        sns.set_palette("husl")

        # Prepare data
        self._prepare_data()

    def _prepare_data(self):
        """Prepare data for visualization"""
        # Ensure positive values for certain visualizations
        self.df['Positive_Profit'] = self.df['Profit'].clip(lower=0)
        self.df['Positive_Profit_Margin'] = self.df['Profit_Margin'].clip(lower=0)

        # Calculate key metrics
        self.total_revenue = self.df['Revenue'].sum()
        self.total_profit = self.df['Profit'].sum()
        self.total_ad_spend = self.df['Ad_Spend'].sum()
        self.avg_satisfaction = self.df['Customer_Satisfaction'].mean()
        self.total_conversions = self.df['Conversions'].sum()

        self.retention_rate = (
            (self.df['Customer_Status'] == 'Returning').sum() / len(self.df) * 100
        )

        self.avg_clv = self.df['CLV_Score'].mean()
        self.avg_roi = self.df['Ad_ROI'].mean()

        # Calculate growth metrics
        if 'Month' in self.df.columns:
            monthly_revenue = self.df.groupby('Month')['Revenue'].sum()
            if len(monthly_revenue) >= 2:
                self.revenue_growth = (
                    (monthly_revenue.iloc[-1] - monthly_revenue.iloc[0])
                    / monthly_revenue.iloc[0] * 100
                )
            else:
                self.revenue_growth = 0
        else:
            self.revenue_growth = 0

    def create_dashboard(self):
        """Create comprehensive professional dashboard"""
        print("\n" + "="*80)
        print("üé® CREATING ENHANCED PROFESSIONAL DASHBOARD")
        print("="*80)

        # Create figure
        self.fig = plt.figure(figsize=self.config.FIGSIZE)
        self.fig.suptitle(
            'Customer Loyalty & Performance Analysis Dashboard\nComprehensive Business Intelligence Report',
            fontsize=26,
            fontweight='bold',
            color=self.config.COLORS['dark'],
            y=0.98
        )

        # Create grid
        gs = GridSpec(4, 5, figure=self.fig, hspace=0.5, wspace=0.4,
                     top=0.93, bottom=0.05, left=0.05, right=0.97)

        # Row 1: KPI Cards (full width)
        self._create_enhanced_kpi_header(gs[0, :])

        # Row 2: Main analytics
        self._create_revenue_trend_chart(gs[1, :3])
        self._create_customer_segmentation(gs[1, 3:])

        # Row 3: Performance metrics
        self._create_campaign_performance(gs[2, 0:2])
        self._create_channel_analysis(gs[2, 2:4])
        self._create_regional_heatmap(gs[2, 4])

        # Row 4: Deep dive analytics
        self._create_satisfaction_analysis(gs[3, 0:2])
        self._create_roi_analysis(gs[3, 2:4])
        self._create_insights_panel(gs[3, 4])

        plt.tight_layout()
        return self.fig

    def _create_enhanced_kpi_header(self, position):
        """Create enhanced KPI header with icons and trends"""
        ax = self.fig.add_subplot(position)
        ax.axis('off')

        kpis = [
            {
                'title': 'TOTAL REVENUE',
                'value': f'${self.total_revenue/1000:.1f}K',
                'subtitle': f'Growth: {self.revenue_growth:+.1f}%',
                'icon': 'üí∞',
                'color': self.config.COLORS['primary']
            },
            {
                'title': 'NET PROFIT',
                'value': f'${self.total_profit/1000:.1f}K',
                'subtitle': f'Margin: {self.total_profit/self.total_revenue*100:.1f}%',
                'icon': 'üìà',
                'color': self.config.COLORS['success']
            },
            {
                'title': 'CUSTOMER RETENTION',
                'value': f'{self.retention_rate:.1f}%',
                'subtitle': f'Returning: {(self.df["Customer_Status"]=="Returning").sum()}',
                'icon': 'üîÑ',
                'color': self.config.COLORS['secondary']
            },
            {
                'title': 'AVG SATISFACTION',
                'value': f'{self.avg_satisfaction:.1f}/10',
                'subtitle': f'Total: {len(self.df)} customers',
                'icon': '‚≠ê',
                'color': self.config.COLORS['warning']
            },
            {
                'title': 'AD ROI',
                'value': f'{self.avg_roi:.0f}%',
                'subtitle': f'Spend: ${self.total_ad_spend/1000:.1f}K',
                'icon': 'üéØ',
                'color': self.config.COLORS['accent1']
            },
            {
                'title': 'CONVERSIONS',
                'value': f'{self.total_conversions:,.0f}',
                'subtitle': f'Avg: {self.total_conversions/len(self.df):.1f}/order',
                'icon': '‚úÖ',
                'color': self.config.COLORS['gradient1']
            },
        ]

        n_kpis = len(kpis)
        box_width = 0.95 / n_kpis
        box_height = 0.7

        for i, kpi in enumerate(kpis):
            x_pos = i * box_width + 0.025

            # Create gradient box
            box = FancyBboxPatch(
                (x_pos, 0.15), box_width * 0.95, box_height,
                boxstyle="round,pad=0.02,rounding_size=0.05",
                facecolor=kpi['color'],
                alpha=0.95,
                edgecolor='white',
                linewidth=3,
                transform=ax.transAxes,
                zorder=10
            )
            ax.add_patch(box)

            # Add shadow effect
            shadow = FancyBboxPatch(
                (x_pos + 0.005, 0.145), box_width * 0.95, box_height,
                boxstyle="round,pad=0.02,rounding_size=0.05",
                facecolor='gray',
                alpha=0.2,
                edgecolor='none',
                transform=ax.transAxes,
                zorder=9
            )
            ax.add_patch(shadow)

            # Icon
            ax.text(
                x_pos + box_width * 0.475, 0.75,
                kpi['icon'],
                fontsize=32,
                ha='center',
                va='center',
                transform=ax.transAxes,
                color='white',
                weight='bold',
                zorder=11
            )

            # Value
            ax.text(
                x_pos + box_width * 0.475, 0.55,
                kpi['value'],
                fontsize=22,
                fontweight='bold',
                ha='center',
                va='center',
                transform=ax.transAxes,
                color='white',
                zorder=11
            )

            # Title
            ax.text(
                x_pos + box_width * 0.475, 0.38,
                kpi['title'],
                fontsize=10,
                ha='center',
                va='center',
                transform=ax.transAxes,
                color='white',
                weight='bold',
                zorder=11
            )

            # Subtitle
            ax.text(
                x_pos + box_width * 0.475, 0.25,
                kpi['subtitle'],
                fontsize=9,
                ha='center',
                va='center',
                transform=ax.transAxes,
                color='white',
                alpha=0.9,
                zorder=11
            )

    def _create_revenue_trend_chart(self, position):
        """Create revenue and profit trend over time"""
        ax = self.fig.add_subplot(position)

        monthly_data = self.df.groupby('Month_Name').agg({
            'Revenue': 'sum',
            'Profit': 'sum',
            'Cost': 'sum'
        }).reset_index()

        x = range(len(monthly_data))

        # Plot bars
        width = 0.35
        bars1 = ax.bar(
            [i - width/2 for i in x],
            monthly_data['Revenue'],
            width,
            label='Revenue',
            color=self.config.COLORS['primary'],
            alpha=0.8,
            edgecolor='white',
            linewidth=2
        )

        bars2 = ax.bar(
            [i + width/2 for i in x],
            monthly_data['Profit'],
            width,
            label='Profit',
            color=self.config.COLORS['success'],
            alpha=0.8,
            edgecolor='white',
            linewidth=2
        )

        # Add trend line for revenue
        z = np.polyfit(x, monthly_data['Revenue'], 2)
        p = np.poly1d(z)
        ax.plot(
            x,
            p(x),
            color=self.config.COLORS['danger'],
            linewidth=3,
            linestyle='--',
            label='Revenue Trend',
            alpha=0.7
        )

        # Add value labels on bars
        for bars in [bars1, bars2]:
            for bar in bars:
                height = bar.get_height()
                ax.text(
                    bar.get_x() + bar.get_width()/2.,
                    height,
                    f'${height/1000:.1f}K',
                    ha='center',
                    va='bottom',
                    fontsize=9,
                    fontweight='bold'
                )

        ax.set_title(
            'Revenue & Profit Trend Analysis',
            fontsize=16,
            fontweight='bold',
            pad=15,
            color=self.config.COLORS['dark']
        )
        ax.set_xlabel('Month', fontsize=12, fontweight='bold')
        ax.set_ylabel('Amount ($)', fontsize=12, fontweight='bold')
        ax.set_xticks(x)
        ax.set_xticklabels(monthly_data['Month_Name'], rotation=45, ha='right')
        ax.legend(loc='upper left', fontsize=11, framealpha=0.9)
        ax.grid(True, alpha=0.3, linestyle='--', axis='y')
        ax.set_axisbelow(True)

        # Add background color
        ax.set_facecolor('#f8f9fa')

    def _create_customer_segmentation(self, position):
        """Create customer segmentation analysis"""
        ax = self.fig.add_subplot(position)

        # Calculate metrics by customer status
        segment_data = self.df.groupby('Customer_Status').agg({
            'Revenue': ['sum', 'mean', 'count'],
            'Customer_Satisfaction': 'mean',
            'CLV_Score': 'mean'
        }).round(2)

        statuses = segment_data.index

        # Create grouped metrics
        metrics = {
            'Avg Revenue': segment_data[('Revenue', 'mean')].values,
            'Avg CLV': segment_data[('CLV_Score', 'mean')].values,
            'Avg Satisfaction': segment_data[('Customer_Satisfaction', 'mean')].values * 50  # Scale for visibility
        }

        x = np.arange(len(statuses))
        width = 0.25
        colors = [self.config.COLORS['primary'], self.config.COLORS['accent1'], self.config.COLORS['warning']]

        for i, (metric, values) in enumerate(metrics.items()):
            offset = width * (i - 1)
            bars = ax.bar(
                x + offset,
                values,
                width,
                label=metric,
                color=colors[i],
                alpha=0.85,
                edgecolor='white',
                linewidth=1.5
            )

            # Add value labels
            for bar in bars:
                height = bar.get_height()
                ax.text(
                    bar.get_x() + bar.get_width()/2.,
                    height,
                    f'{height:.0f}',
                    ha='center',
                    va='bottom',
                    fontsize=9,
                    fontweight='bold'
                )

        # Add customer count as text
        for i, status in enumerate(statuses):
            count = segment_data.loc[status, ('Revenue', 'count')]
            ax.text(
                i,
                ax.get_ylim()[1] * 0.95,
                f'n={int(count)}',
                ha='center',
                va='top',
                fontsize=11,
                fontweight='bold',
                bbox=dict(boxstyle='round,pad=0.5', facecolor='yellow', alpha=0.7)
            )

        ax.set_title(
            'Customer Segmentation Analysis',
            fontsize=16,
            fontweight='bold',
            pad=15,
            color=self.config.COLORS['dark']
        )
        ax.set_xlabel('Customer Status', fontsize=12, fontweight='bold')
        ax.set_ylabel('Value', fontsize=12, fontweight='bold')
        ax.set_xticks(x)
        ax.set_xticklabels(statuses)
        ax.legend(loc='upper left', fontsize=10, framealpha=0.9)
        ax.grid(True, alpha=0.3, axis='y')
        ax.set_facecolor('#f8f9fa')

    def _create_campaign_performance(self, position):
        """Create campaign performance comparison"""
        ax = self.fig.add_subplot(position)

        campaign_perf = self.df.groupby('Campaign_Type').agg({
            'Revenue': 'mean',
            'Profit': 'mean',
            'Customer_Satisfaction': 'mean',
            'Conversions': 'mean',
            'Ad_ROI': 'mean'
        }).sort_values('Revenue', ascending=True)

        # Normalize metrics for radar-like comparison
        metrics_normalized = {}
        for col in campaign_perf.columns:
            min_val = campaign_perf[col].min()
            max_val = campaign_perf[col].max()
            if max_val > min_val:
                metrics_normalized[col] = (campaign_perf[col] - min_val) / (max_val - min_val)
            else:
                metrics_normalized[col] = pd.Series([0.5] * len(campaign_perf), index=campaign_perf.index)

        df_norm = pd.DataFrame(metrics_normalized)

        # Create stacked horizontal bars
        y_pos = np.arange(len(campaign_perf))
        left = np.zeros(len(campaign_perf))

        colors = [
            self.config.COLORS['primary'],
            self.config.COLORS['success'],
            self.config.COLORS['warning'],
            self.config.COLORS['accent1'],
            self.config.COLORS['secondary']
        ]

        for i, col in enumerate(df_norm.columns):
            ax.barh(
                y_pos,
                df_norm[col],
                left=left,
                height=0.6,
                label=col.replace('_', ' '),
                color=colors[i % len(colors)],
                alpha=0.85,
                edgecolor='white',
                linewidth=1.5
            )
            left += df_norm[col]

        ax.set_title(
            'Campaign Performance Matrix\n(Normalized Metrics)',
            fontsize=14,
            fontweight='bold',
            pad=15,
            color=self.config.COLORS['dark']
        )
        ax.set_yticks(y_pos)
        ax.set_yticklabels(campaign_perf.index, fontsize=11)
        ax.set_xlabel('Normalized Performance Score', fontsize=11, fontweight='bold')
        ax.legend(loc='lower right', fontsize=9, framealpha=0.9, ncol=2)
        ax.grid(True, alpha=0.3, axis='x')
        ax.set_facecolor('#f8f9fa')
        ax.set_xlim(0, left.max() * 1.1)

    def _create_channel_analysis(self, position):
        """Create channel performance bubble chart"""
        ax = self.fig.add_subplot(position)

        channel_data = self.df.groupby('Channel').agg({
            'Revenue': 'mean',
            'Customer_Satisfaction': 'mean',
            'Conversions': 'sum',
            'Ad_ROI': 'mean'
        })

        x = channel_data['Customer_Satisfaction']
        y = channel_data['Ad_ROI']
        sizes = channel_data['Revenue']
        colors_map = channel_data['Conversions']

        # Normalize sizes for better visualization
        size_min, size_max = sizes.min(), sizes.max()
        if size_max > size_min:
            sizes_norm = ((sizes - size_min) / (size_max - size_min) * 2000) + 300
        else:
            sizes_norm = pd.Series([500] * len(sizes), index=sizes.index)

        scatter = ax.scatter(
            x, y,
            s=sizes_norm,
            c=colors_map,
            cmap='viridis',
            alpha=0.7,
            edgecolors='black',
            linewidth=2
        )

        # Add channel labels
        for channel in channel_data.index:
            ax.annotate(
                channel,
                (x[channel], y[channel]),
                fontsize=10,
                fontweight='bold',
                ha='center',
                va='center',
                bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.7, edgecolor='black')
            )

        ax.set_title(
            'Channel Performance Analysis\n(Size=Revenue, Color=Conversions)',
            fontsize=14,
            fontweight='bold',
            pad=15,
            color=self.config.COLORS['dark']
        )
        ax.set_xlabel('Avg Customer Satisfaction', fontsize=11, fontweight='bold')
        ax.set_ylabel('Avg ROI (%)', fontsize=11, fontweight='bold')
        ax.grid(True, alpha=0.3, linestyle='--')
        ax.set_facecolor('#f8f9fa')

        # Add colorbar
        cbar = plt.colorbar(scatter, ax=ax)
        cbar.set_label('Total Conversions', fontsize=10, fontweight='bold')

        # Add quadrant lines
        ax.axhline(y.mean(), color='red', linestyle='--', alpha=0.5, linewidth=1)
        ax.axvline(x.mean(), color='red', linestyle='--', alpha=0.5, linewidth=1)

    def _create_regional_heatmap(self, position):
        """Create regional performance heatmap"""
        ax = self.fig.add_subplot(position)

        # Pivot table for heatmap
        regional_data = self.df.groupby(['Region', 'Customer_Status']).agg({
            'Revenue': 'mean'
        }).reset_index()

        pivot_table = regional_data.pivot(
            index='Region',
            columns='Customer_Status',
            values='Revenue'
        ).fillna(0)

        # Create heatmap
        sns.heatmap(
            pivot_table,
            annot=True,
            fmt='.0f',
            cmap='YlOrRd',
            cbar_kws={'label': 'Avg Revenue ($)'},
            linewidths=2,
            linecolor='white',
            ax=ax,
            square=True
        )

        ax.set_title(
            'Regional\nPerformance\nHeatmap',
            fontsize=12,
            fontweight='bold',
            pad=10,
            color=self.config.COLORS['dark']
        )
        ax.set_xlabel('Customer Status', fontsize=10, fontweight='bold')
        ax.set_ylabel('Region', fontsize=10, fontweight='bold')
        plt.setp(ax.get_xticklabels(), rotation=45, ha='right')
        plt.setp(ax.get_yticklabels(), rotation=0)

    def _create_satisfaction_analysis(self, position):
        """Create satisfaction distribution and analysis"""
        ax = self.fig.add_subplot(position)

        # Create violin plot with overlay
        satisfaction_by_status = []
        labels = []
        for status in self.df['Customer_Status'].unique():
            satisfaction_by_status.append(
                self.df[self.df['Customer_Status'] == status]['Customer_Satisfaction']
            )
            labels.append(status)

        parts = ax.violinplot(
            satisfaction_by_status,
            positions=range(len(labels)),
            showmeans=True,
            showextrema=True,
            widths=0.7
        )

        # Customize violin plot colors
        for i, pc in enumerate(parts['bodies']):
            pc.set_facecolor(list(self.config.COLORS.values())[i % len(self.config.COLORS)])
            pc.set_alpha(0.7)
            pc.set_edgecolor('black')
            pc.set_linewidth(2)

        # Overlay box plot
        bp = ax.boxplot(
            satisfaction_by_status,
            positions=range(len(labels)),
            widths=0.3,
            patch_artist=True,
            boxprops=dict(facecolor='white', alpha=0.6, linewidth=2),
            medianprops=dict(color='red', linewidth=3),
            whiskerprops=dict(linewidth=2),
            capprops=dict(linewidth=2)
        )

        ax.set_title(
            'Customer Satisfaction Distribution\nby Status',
            fontsize=14,
            fontweight='bold',
            pad=15,
            color=self.config.COLORS['dark']
        )
        ax.set_xlabel('Customer Status', fontsize=11, fontweight='bold')
        ax.set_ylabel('Satisfaction Score', fontsize=11, fontweight='bold')
        ax.set_xticks(range(len(labels)))
        ax.set_xticklabels(labels)
        ax.set_ylim(0, 11)
        ax.grid(True, alpha=0.3, axis='y')
        ax.set_facecolor('#f8f9fa')

        # Add mean line
        ax.axhline(
            self.avg_satisfaction,
            color='red',
            linestyle='--',
            linewidth=2,
            alpha=0.7,
            label=f'Overall Mean: {self.avg_satisfaction:.1f}'
        )
        ax.legend(loc='upper right', fontsize=10)

    def _create_roi_analysis(self, position):
        """Create ROI analysis chart"""
        ax = self.fig.add_subplot(position)

        # Scatter plot: Ad Spend vs Revenue with ROI color coding
        scatter = ax.scatter(
            self.df['Ad_Spend'],
            self.df['Revenue'],
            c=self.df['Ad_ROI'],
            s=self.df['Conversions'] * 20,
            cmap='RdYlGn',
            alpha=0.6,
            edgecolors='black',
            linewidth=0.5,
            vmin=-50,
            vmax=200
        )

        # Add break-even line
        max_val = max(self.df['Ad_Spend'].max(), self.df['Revenue'].max())
        ax.plot([0, max_val], [0, max_val], 'r--', linewidth=2, alpha=0.7, label='Break-even Line')

        # Add trend line
        z = np.polyfit(self.df['Ad_Spend'], self.df['Revenue'], 1)
        p = np.poly1d(z)
        x_trend = np.linspace(self.df['Ad_Spend'].min(), self.df['Ad_Spend'].max(), 100)
        ax.plot(x_trend, p(x_trend), 'b-', linewidth=3, alpha=0.5, label=f'Trend (slope={z[0]:.2f})')

        ax.set_title(
            'ROI Analysis: Ad Spend vs Revenue\n(Size=Conversions, Color=ROI%)',
            fontsize=14,
            fontweight='bold',
            pad=15,
            color=self.config.COLORS['dark']
        )
        ax.set_xlabel('Ad Spend ($)', fontsize=11, fontweight='bold')
        ax.set_ylabel('Revenue ($)', fontsize=11, fontweight='bold')
        ax.legend(loc='upper left', fontsize=10, framealpha=0.9)
        ax.grid(True, alpha=0.3)
        ax.set_facecolor('#f8f9fa')

        # Add colorbar
        cbar = plt.colorbar(scatter, ax=ax)
        cbar.set_label('ROI (%)', fontsize=10, fontweight='bold')

        # Add quadrant analysis text
        profitable = (self.df['Revenue'] > self.df['Ad_Spend']).sum()
        total = len(self.df)
        ax.text(
            0.95, 0.05,
            f'Profitable: {profitable}/{total} ({profitable/total*100:.1f}%)',
            transform=ax.transAxes,
            fontsize=10,
            ha='right',
            va='bottom',
            bbox=dict(boxstyle='round,pad=0.5', facecolor='yellow', alpha=0.8)
        )

    def _create_insights_panel(self, position):
        """Create insights and recommendations panel"""
        ax = self.fig.add_subplot(position)
        ax.axis('off')

        # Generate insights
        insights = self._generate_advanced_insights()

        # Create styled text box
        insight_text = "üîç KEY INSIGHTS\n" + "‚îÄ" * 25 + "\n\n"

        for i, insight in enumerate(insights[:8], 1):
            insight_text += f"{i}. {insight}\n\n"

        insight_text += "\nüöÄ ACTIONS\n" + "‚îÄ" * 25 + "\n"
        actions = [
            "‚Üó Scale high-ROI channels",
            "üéØ Target returning customers",
            "üìä A/B test underperformers",
            "üí° Optimize ad spend allocation",
            "‚≠ê Boost satisfaction scores",
        ]

        for action in actions:
            insight_text += f"{action}\n"

        # Display text with styling
        ax.text(
            0.5, 0.5,
            insight_text,
            transform=ax.transAxes,
            fontsize=9,
            verticalalignment='center',
            horizontalalignment='center',
            bbox=dict(
                boxstyle='round,pad=1',
                facecolor=self.config.COLORS['light'],
                alpha=0.95,
                edgecolor=self.config.COLORS['primary'],
                linewidth=3
            ),
            family='monospace'
        )

    def _generate_advanced_insights(self):
        """Generate advanced insights from data"""
        insights = []

        try:
            # 1. Retention insight
            if self.retention_rate >= 60:
                insights.append(f"Strong {self.retention_rate:.1f}% retention - Leverage loyalty")
            else:
                insights.append(f"Low {self.retention_rate:.1f}% retention - Implement programs")

            # 2. Revenue per customer type
            if 'Customer_Status' in self.df.columns:
                new_rev = self.df[self.df['Customer_Status'] == 'New']['Revenue'].mean()
                ret_rev = self.df[self.df['Customer_Status'] == 'Returning']['Revenue'].mean()
                if ret_rev > new_rev:
                    ratio = ret_rev / new_rev
                    insights.append(f"Returning customers worth {ratio:.1f}x more")

            # 3. Best performing campaign
            best_campaign = self.df.groupby('Campaign_Type')['Profit'].mean().idxmax()
            insights.append(f"'{best_campaign}' campaigns most profitable")

            # 4. Best channel
            best_channel = self.df.groupby('Channel')['Ad_ROI'].mean().idxmax()
            best_roi = self.df.groupby('Channel')['Ad_ROI'].mean().max()
            insights.append(f"'{best_channel}' delivers {best_roi:.0f}% ROI")

            # 5. Satisfaction correlation
            if self.avg_satisfaction < 7:
                insights.append(f"Satisfaction at {self.avg_satisfaction:.1f} - Needs attention")

            # 6. Regional opportunity
            regional_rev = self.df.groupby('Region')['Revenue'].sum()
            top_region = regional_rev.idxmax()
            insights.append(f"'{top_region}' region generates most revenue")

            # 7. Conversion efficiency
            avg_conv_rate = self.df['Conversion_Rate'].mean()
            insights.append(f"Avg conversion rate: {avg_conv_rate:.1f}%")

            # 8. Profit margin insight
            if self.total_profit / self.total_revenue < 0.2:
                insights.append("Profit margins <20% - Optimize costs")
            else:
                insights.append("Healthy profit margins >20%")

        except Exception as e:
            insights.append(f"Analysis error: {str(e)[:30]}")

        return insights

    def save_dashboard(self, filename=None, output_dir=None):
        """Save dashboard to file"""
        if output_dir is None:
            output_dir = self.config.OUTPUT_DIR

        # Create output directory if it doesn't exist
        Path(output_dir).mkdir(parents=True, exist_ok=True)

        if filename is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"loyalty_dashboard_{timestamp}.png"

        filepath = os.path.join(output_dir, filename)

        if self.fig is not None:
            self.fig.savefig(
                filepath,
                dpi=self.config.DPI,
                bbox_inches='tight',
                facecolor='white',
                edgecolor='none'
            )
            print(f"\n‚úÖ Dashboard saved: {filepath}")
            return filepath

        return None

    def print_executive_summary(self):
        """Print comprehensive executive summary"""
        print("\n" + "="*80)
        print("üìä EXECUTIVE SUMMARY REPORT")
        print("="*80)

        print(f"\nüìÖ Analysis Period:")
        print(f"   From: {self.df['Date'].min().strftime('%Y-%m-%d')}")
        print(f"   To:   {self.df['Date'].max().strftime('%Y-%m-%d')}")
        print(f"   Duration: {(self.df['Date'].max() - self.df['Date'].min()).days} days")

        print(f"\nüí∞ FINANCIAL PERFORMANCE:")
        print(f"   Total Revenue:    ${self.total_revenue:,.2f}")
        print(f"   Total Profit:     ${self.total_profit:,.2f}")
        print(f"   Total Ad Spend:   ${self.total_ad_spend:,.2f}")
        print(f"   Profit Margin:    {self.total_profit/self.total_revenue*100:.2f}%")
        print(f"   Avg ROI:          {self.avg_roi:.1f}%")
        print(f"   Revenue Growth:   {self.revenue_growth:+.1f}%")

        print(f"\nüë• CUSTOMER METRICS:")
        print(f"   Total Customers:     {len(self.df):,}")
        print(f"   Retention Rate:      {self.retention_rate:.1f}%")
        print(f"   Avg Satisfaction:    {self.avg_satisfaction:.2f}/10")
        print(f"   Avg CLV:             ${self.avg_clv:,.2f}")
        print(f"   Total Conversions:   {self.total_conversions:,.0f}")

        print(f"\nüéØ TOP PERFORMERS:")

        # Top campaign
        top_campaign = self.df.groupby('Campaign_Type').agg({
            'Revenue': 'sum',
            'Profit': 'sum'
        }).sort_values('Profit', ascending=False)
        print(f"\n   Best Campaign: {top_campaign.index[0]}")
        print(f"      Revenue: ${top_campaign.iloc[0]['Revenue']:,.2f}")
        print(f"      Profit:  ${top_campaign.iloc[0]['Profit']:,.2f}")

        # Top channel
        top_channel = self.df.groupby('Channel').agg({
            'Ad_ROI': 'mean',
            'Revenue': 'sum'
        }).sort_values('Ad_ROI', ascending=False)
        print(f"\n   Best Channel: {top_channel.index[0]}")
        print(f"      ROI:     {top_channel.iloc[0]['Ad_ROI']:.1f}%")
        print(f"      Revenue: ${top_channel.iloc[0]['Revenue']:,.2f}")

        # Top region
        top_region = self.df.groupby('Region')['Revenue'].sum().sort_values(ascending=False)
        print(f"\n   Best Region: {top_region.index[0]}")
        print(f"      Revenue: ${top_region.iloc[0]:,.2f}")
        print(f"      Share:   {top_region.iloc[0]/self.total_revenue*100:.1f}%")

        print(f"\nüîç KEY INSIGHTS:")
        insights = self._generate_advanced_insights()
        for i, insight in enumerate(insights[:5], 1):
            print(f"   {i}. {insight}")

        print("\n" + "="*80)

# ============================================================================
# MAIN EXECUTION
# ============================================================================

def main():
    """Main execution function"""

    print("\n" + "="*80)
    print("üöÄ ENHANCED CUSTOMER LOYALTY ANALYSIS SYSTEM")
    print("="*80)
    print("\nVersion: 2.0 - Production Ready")
    print("Features: Advanced Analytics | Professional Dashboard | AI Insights")
    print("="*80)

    # Initialize configuration
    config = Config()

    # Step 1: Load Data
    print("\n" + "‚îÄ"*80)
    print("STEP 1: DATA LOADING")
    print("‚îÄ"*80)

    df = None

    # Try to load from PDF first
    if os.path.exists(config.DATA_FILE_PATH):
        print(f"\nüìÅ Found data file: {config.DATA_FILE_PATH}")
        df = DataLoader.load_from_pdf(config.DATA_FILE_PATH)
    else:
        print(f"\n‚ö†Ô∏è  Data file not found: {config.DATA_FILE_PATH}")

    # If PDF loading failed, create sample data
    if df is None or len(df) == 0:
        print("\n‚ö†Ô∏è  PDF loading failed or no data. Creating sample dataset...")
        df = DataLoader.create_sample_data(n_samples=250)

    # Step 2: Clean and Validate
    print("\n" + "‚îÄ"*80)
    print("STEP 2: DATA CLEANING & VALIDATION")
    print("‚îÄ"*80)

    df = DataCleaner.clean_and_validate(df)

    if df is None or len(df) == 0:
        print("\n‚ùå Data cleaning failed. Cannot proceed.")
        return

    # Print data quality report
    DataCleaner.print_data_quality_report(df)

    # Step 3: Create Dashboard
    print("\n" + "‚îÄ"*80)
    print("STEP 3: CREATING PROFESSIONAL DASHBOARD")
    print("‚îÄ"*80)

    dashboard = EnhancedLoyaltyDashboard(df, config)

    # Create dashboard
    fig = dashboard.create_dashboard()

    # Step 4: Generate Reports
    print("\n" + "‚îÄ"*80)
    print("STEP 4: GENERATING REPORTS")
    print("‚îÄ"*80)

    dashboard.print_executive_summary()

    # Step 5: Save outputs
    print("\n" + "‚îÄ"*80)
    print("STEP 5: SAVING OUTPUTS")
    print("‚îÄ"*80)

    # Save dashboard
    saved_path = dashboard.save_dashboard()

    # Save data to CSV for reference
    output_csv = os.path.join(config.OUTPUT_DIR, f"processed_data_{datetime.now().strftime('%Y%m%d')}.csv")
    df.to_csv(output_csv, index=False)
    print(f"‚úÖ Data saved: {output_csv}")

    # Display dashboard
    print("\n" + "‚îÄ"*80)
    print("DISPLAYING DASHBOARD")
    print("‚îÄ"*80)
    print("\nüìä Dashboard is now displayed. Close the window to exit.")

    plt.show()

    print("\n" + "="*80)
    print("‚úÖ ANALYSIS COMPLETED SUCCESSFULLY!")
    print("="*80)
    print(f"\nüìÅ All outputs saved to: {config.OUTPUT_DIR}/")
    print("\nüéâ Thank you for using the Enhanced Loyalty Analysis System!")
    print("="*80 + "\n")

# ============================================================================
# ENTRY POINT
# ============================================================================

if __name__ == "__main__":
    """Entry point for the application"""

    # Set pandas display options
    pd.set_option('display.max_columns', None)
    pd.set_option('display.width', 120)
    pd.set_option('display.precision', 2)

    # Set matplotlib backend
    try:
        import matplotlib
        matplotlib.use('TkAgg')  # or 'Qt5Agg' depending on your system
    except:
        pass

    # Run the application
    try:
        main()
    except KeyboardInterrupt:
        print("\n\n‚ö†Ô∏è  Analysis interrupted by user")
        print("‚ùå Exiting...")
    except Exception as e:
        print(f"\n‚ùå CRITICAL ERROR: {e}")
        print("\nüìã Full traceback:")
        traceback.print_exc()
        print("\nüí° Tip: Check your Python environment and install required packages:")
        print("   pip install pandas numpy matplotlib seaborn tabula-py camelot-py pdfplumber")